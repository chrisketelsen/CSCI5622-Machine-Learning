# Final Project 

The final project offers you an opportunity to apply machine learning techniques on a problem that _you_ care about beyond the scope of homeworks. It also helps you practice a diverse set of skills, including working in a team and providing constructive feedback.

# Timeline 

- **Project Brainstorming**: Jan 17th -- starting from the first day, getting yourself in ML mode 
- **Group Formation Due**: Feb 2nd   
- **Project Proposal Due**: Mar 2nd 
- **Project Pitches**: Mar 5th 
- **Peer Pitch Feedback Due**: Mar 12th  
- **Midpoint Spotlight Due**: Apr 6th  
- **Peer Spotlight Feedback Due**: Apr 11th  
- **Final Project Poster Session**: May 2nd  
- **Final Project Report**: May 4th  

# Project Brainstorming 

We will use Piazza and office hours heavily to discuss final project ideas. Please use `#project_ideas` to tag corresponding posts on Piazza. Course staff will offer feedback to these posts.

A good project should 

- be an interesting well-motivated problem;
- have readily available data, or a clear plan to gather the dataset by March 15th;
- can be formulated or partially addressed with machine learning techniques;
- have a solution (ideally multiple solutions) that you can implement within the scope of this class.

**Note**: We prefer projects that are technique and/or application driven. For example, a project could start with a group interested 
in learning more about [adversarial neural networks](https://blog.openai.com/adversarial-example-research/) and how they could be used
to thwart facial recognition systems.  What we **do not** prefer are Kaggle-based projects where a group chooses a dataset online
and throws an unfocused kitchen sink at it.  Such projects will be met with intense scrutiny and multiple raised eyebrows. 

# Groups 

You must form a group of 4-5 students enrolled in this course and make a post on Piazza with your names (use `#project_groups` to tag the post) by 11:59pm on Feb 2nd. Participation in brainstorming project ideas is a great way to find other students with similar interests. It is important to convince your peers that your idea has merit both in academia and in industry.

# Final Project Proposal 

Each group will submit a proposal of **at most** two pages and a presentation of **at most** three slides by 11:59pm on Mar 2nd on Moodle.  In addition, each group will make a single post on Piazza attaching their slides and proposal using the tag `#project_pitches`. Finally, each group will make a presentation of three minutes in class on Mar 5th.

A good proposal should

- explain why the project is worth studying;
- explain why machine learning techniques are appropriate;
- demonstrate that you (will) have access to datasets;
- present initial thoughts of possible approaches.

# Peer Feedback for Project Proposal

Each student will provide feedback to one project from other groups in the Follow-up Discussion section of the associated Piazza post by 11:59pm on Oct 25. The feedback should use the following template:

- What I like about this proposal
- What I would have done differently (practical constructive feedback for improvements)
- What I wish that this project can achieve with unlimited resources (moonshot ideas)

Your feedback will be evaluated based on whether it is clear and constructive.

# Midpoint Spotlight

Prepare at most three slides to describe

- What you have done so far
- What kind of advice that you are seeking.

Due to limited time, you will post your slides on Piazza using the tag `#project_spotlight` rather than giving a formal presentation. 

# Midpoint Peer Feedback

Each student will provide feedback to one projects from other groups in the Follow-up Discussion section of the associated Piazza post by 11:59pm on Apr 11th. The feedback should use the following template:

- What I like about the current progress
- What I would improve over what has been done
- What I would try in the next three weeks

Your feedback will be evaluated based on whether it is clear and constructive.

# Final Poster Presentation

The poster presentation will be on May 2nd (location and time TBD). In the poster presentation you will present a poster in the same format of a research conference. You need to

- Explain what you did and what you think is the most exciting thing from this project
- What challenges you had
- Review how well you did

This poster session will last roughly one and a half hours. Course staff and guess reviewers will visit each poster to grade your poster presentation.

# Final report

The final report is due on May 4th on Moodle. List group members in the report and sort the name alphabetically. You report should explain what you did and what results you achieved. This document should make it clear:

- Why this project is a good (or bad) idea,
- What you did,
- Whether your technique worked or not,
- Who did what.

Please do not go over 2500 words unless you have a really good reason. Images are a much better use of space than words, usually (there's no limit on including images, but use good judgment and be selective).

We will use the NIPS format. You can download the LaTex template [here](https://nips.cc/Conferences/2017/PaperInformation/StyleFiles). We strongly recommend using LaTex, but you can use this [Microsoft word template](http://web.archive.org/web/20130424174118/http://media.nips.cc/Conferences/2013/Styles/nips2013.docx) from 2013. All submissions must be in PDF format.

The final report will be evaluated based on the following aspects:

- **Writeup**: Does the writeup explain what you did in a way that is clear and effective?

- **Technical Soundness**: Did you use the appropriate tools for the problem? Were they relevant to this class?

- **Effort**: The amount of effort that you spend in the process.

- **Performance**: How did your techniques perform?

Tips for a good report: 

- Provide an error analysis. An error analysis must contain examples from the development set that you get wrong. You should show those examples and explain why (in terms of features or the model) they have the wrong answer. You should have been doing this all along as your derive new approaches, but this is your final inspection of your errors. The feature or model problems you discover should not be trivial features you could add easily. Instead, these should be features or models that are difficult to correct. An error analysis is not the same thing as simply presenting the error matrix, as it does not inspect any individual examples.

- Explain the motivation for your approaches. For example, features shouldn't come out of nowhere; you should have a clear domain-specific story for how you derived the features or an error analysis motivations for the features you create.

# Grade Distribution 

- Proposal: 10% 
- Proposal peer feedback: 5% 
- Midpoint spotlight: 10% 
- Midpoint spotlight peer feedback: 5% 
- Poster and Presentation: 20% 
- Final Report: 50% 
















